<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Qihuang Zhong (钟起煌)</title>
    <link rel="icon" type="image/x-icon" href="whu.png"/>
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 1em">
    <img src="whu2.png" alt="WHU" style="width:auto; height:1.5em" />
    Qihuang Zhong (钟起煌)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="publication.html">Publications</a></div>
    <!-- <div class="menu-item"><a href="talk.html">Invited Talks</a></div>
    <div class="menu-item"><a href="service.html">Professional Services</a></div> -->
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
    <p>[ <a href="#bio">Short Bio</a>,
	 <a href="#interest">Research Interests</a>,
         <a href="#news">News</a>,
         <a href="#job">Job Experience</a>,
         <a href="#edu">Education</a>,
	 <a href="#award">Honors</a>
         ]</p>

    <table class="imgtable"><tr valign="top">
        <td><img src="zqh2.jpg" alt="zqh-self" style="width:auto; height:12em" /></td>
        <td align="left">
            <p><span style="font-size: 125%"><b>Qihuang Zhong</b></span></p>
            <p>
                Ph.D. student at Wuhan University,<br>
                <a href="https://cs.whu.edu.cn/" target="_blank">School of Computer Science</a>, Wuhan, China <br>
            </p>
            <p>
                E-mail: zhongqihuang@whu.edu.cn<br>
                [ <a href="https://scholar.google.com.hk/citations?user=YCL8gkYAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a> ] 
                [ <a href="https://github.com/WHU-ZQH" target="_blank">Github</a> ] 
                [ <a href="https://twitter.com/qihuang_zqh" target="_blank">Twitter</a> ] 
            </p>
        </td>
    </tr></table>
    
    <div>
        <h2><hr><a name="bio"></a>Short Bio</h2>
        <p>
            I am currently pursuing a Ph.D. degree in Artificial Intelligence from the School of Computer Science, Wuhan University. I was a research intern at JD Explore Academy.
            I have authored or co-authored over 10 papers at top conferences and international journals, including ACL, EMNLP, COLING, IEEE TKDE, IEEE TASLP and etc. 
	    I was supported by the Fundamental Research Project for Young Professional from NSFC (首批国自然博士生基金, <a href="https://cs.whu.edu.cn/info/1054/41871.htm" target="_blank">PR</a>) and, was supported by the Youth Talents Support Project - Doctoral Student Special Program (首届中国科协青年人才托举工程-博士生专项, <a href="https://mp.weixin.qq.com/s/KhozoDHnFoNAwJiH4BLRRQ" target="_blank">PR</a>).
            I won the general language understanding (<a href="https://gluebenchmark.com/leaderboard/" target="_blank">GLUE</a>) and more difficult language understanding (<a href="https://super.gluebenchmark.com/leaderboard" target="_blank">SuperGLUE</a>) challenges.
        </p>
    </div>

    <div>
        <h2><hr><a name="interest"></a>Research Interests</h2>
        <ul>
            <li><p><b>Large Language Model</b> <br>
                chain-of-thought, [<u><a href="https://arxiv.org/pdf/2302.10198" target="_blank">ChatGPT vs. BERT (<i>arxiv23</i>)</a></u>],
		    [<u><a href="https://aclanthology.org/2023.findings-emnlp.373.pdf" target="_blank">ChatGPT for NMT (<i>EMNLP23</i>)</a></u>], <br>
                instruction-tuning, <br>
		efficient training/inference, [<u><a href="https://aclanthology.org/2023.emnlp-main.696.pdf" target="_blank">ZSAQ (<i>EMNLP23</i>)</a></u>, 
		    <u><a href="https://arxiv.org/pdf/2402.11890" target="_blank">ATKD (<i>ACL24</i>)</a></u>, <u><a href="https://arxiv.org/pdf/2410.11371" target="_blank">KID (<i>EMNLP24</i>)</a></u>],<br>
                safety. [<u><a href="https://arxiv.org/pdf/2402.11889" target="_blank">ROSE (<i>ACL24</i>)</a></u>]
            </p></li>
            <li><p><b>Discriminative Language Model</b> <br>
                sufficient/efficient pretraining, [<u><a href="https://aclanthology.org/2023.findings-acl.254/" target="_blank">SE4PLMs (<i>ACL23</i>)</a></u>,
		<u><a href="https://aclanthology.org/2023.acl-long.579/" target="_blank">ScTD (<i>ACL23</i>)</a></u>,
		<u><a href="https://ieeexplore.ieee.org/document/10363656" target="_blank">E2S2 (<i>IEEE TKDE</i>)</a></u>, 
                <u><a href="https://arxiv.org/pdf/2302.09268" target="_blank">Vega v1 (<i>Technical report</i>)</a></u>,
                <u><a href="https://arxiv.org/pdf/2212.01853" target="_blank">Vega v2 (<i>Technical report</i>)</a></u>],
                <br>
                effective model adaptation, [<u><a href="https://ieeexplore.ieee.org/document/10475529" target="_blank">PANDA (<i>IEEE TKDE</i>)</a></u>], <br>
                model robustness/generalization. [<u><a href="https://arxiv.org/pdf/2210.05497" target="_blank">FSAM4PLM (<i>EMNLP22</i>)</a></u>,
                <u><a href="https://arxiv.org/pdf/2303.00565" target="_blank">AdaSAM (<i>Neural Networks</i>)</a>], </u>
            </p></li>
            <li><p><b>Natural language Understanding and Generation</b> <br>
                sentiment analysis, [<u><a href="https://ieeexplore.ieee.org/document/10056277" target="_blank">KGAN (<i>IEEE TKDE</i>)</a></u>,
                <u><a href="https://arxiv.org/pdf/2204.07832" target="_blank">C3DA (<i>COLING22</i>)</a></u>,
                <u><a href="https://ieeexplore.ieee.org/document/10184157" target="_blank">UIKA (<i>IEEE TASLP</i>)</a></u>], <br>
                text classification,[<u><a href="https://aclanthology.org/2023.emnlp-main.555.pdf" target="_blank">SE4DA (<i>EMNLP23</i>)</a></u>], <br>
                machine translation and etc.[<u><a href="https://aclanthology.org/2023.acl-short.73/" target="_blank">SE4NMT (<i>ACL23</i>)</a></u>]
            </p></li>
        </ul>
    </div>
    
    <div>
        <h2><hr><a name="news"></a>News</h2>
        <ul>
	   <li><p>
            [05/2025] One long paper has been accepted by <a href="https://2025.aclweb.org" target="_blank">ACL2025</a>.
  	   </p></li>
	   <li><p>
            [09/2024] One long paper has been accepted by <a href="https://2024.emnlp.org" target="_blank">EMNLP2024</a>.
  	   </p></li>
	  <li><p>
            [05/2024] Talk at Student Forum of China Society of Image and Graphics (CSIG学生会员分享论坛：面向通用语言大模型的预训练与微调技术研究, <a href="https://mp.weixin.qq.com/s/l7u79IQUFN-pK8crrfwUqQ" target="_blank">PR</a>).�
  	   </p></li>
	  <li><p>
            [05/2024] Two long papers (1 main and 1 findings) have been accepted by <a href="https://2024.aclweb.org" target="_blank">ACL2024</a>. Cheers! 🥳🥳
  	   </p></li>
	  <li><p>
            [03/2024] One regular paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">IEEE Transactions on Knowledge and Data Engineering</a>.
            [<a href="https://ieeexplore.ieee.org/document/10475529" target="_blank">Paper</a>] [<a href="https://github.com/WHU-ZQH/PANDA" target="_blank">Code</a>] <br>
          </p></li>
	  <li><p>
            [12/2023] One regular paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">IEEE Transactions on Knowledge and Data Engineering</a>.
            [<a href="https://ieeexplore.ieee.org/document/10363656" target="_blank">Paper</a>] [<a href="https://github.com/WHU-ZQH/E2S2" target="_blank">Code</a>] <br>
          </p></li>
          <li><p>
            [10/2023] Three long papers (2 main and 1 findings) have been accepted by <a href="https://2023.emnlp.org" target="_blank">EMNLP2023</a>. Cheers! 🥳🥳
  	   </p></li>
          <li><p>
            [06/2023] One regular paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6570655" target="_blank">IEEE/ACM Transactions on Audio, Speech, and Language Processing</a>.
          </p></li>
	   <li><p>
            [05/2023] Three papers (2 long and 1 short) have been accepted by <a href="https://2023.aclweb.org" target="_blank">ACL2023</a>. Cheers! 🥳🥳
  	   </p></li>
	   <li><p>
            [04/2023] Our Vega series Large Language Models (织女系列自然语言大模型) have won the 2022 Technology Golden Award ("京东集团技术金项奖", the highest tech award at JD.com, Inc).
		[<a href="http://jnews.jd.com/org-new?guid=71ee4d7fb21b4a54a13621702e8599e0" target="_blank">PR</a>]    
  	   </p></li>
	   <li><p>
            [04/2023] New achievement reached! Google Scholar citation count exceeds 100. 🥳
  	   </p></li>
          <li><p>
            [03/2023] We release a report towards making the most of ChatGPT for machine translation. 
	    [<a href="https://arxiv.org/pdf/2303.13780.pdf" target="_blank">Arxiv</a>] 
            [<a href="https://github.com/Romainpkq/ChatGPT4MT" target="_blank">Code</a>] <img src="https://img.shields.io/github/stars/Romainpkq/ChatGPT4MT?style=social"/> <br>
          </p></li>
          <li><p>
            [02/2023] One regular paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">IEEE Transactions on Knowledge and Data Engineering</a>.
            [<a href="https://ieeexplore.ieee.org/document/10056277/" target="_blank">Paper</a>] [<a href="https://github.com/WHU-ZQH/KGAN" target="_blank">Code</a>] <br>
          </p></li>
          <li><p>
            [02/2023] We release a report about language understanding ability of ChatGPT. [<a href="https://arxiv.org/pdf/2302.10198.pdf" target="_blank">Arxiv</a>] 
            [<a href="https://github.com/WHU-ZQH/ChatGPT-vs.-BERT" target="_blank">Code</a>] <img src="https://img.shields.io/github/stars/WHU-ZQH/ChatGPT-vs.-BERT?style=social"/> <br>
          </p></li>
          <li><p>
            [10/2022] Our <a href="https://arxiv.org/pdf/2212.01853.pdf" target="_blank">Vega v2</a> model got <b>1st</b> place on the difficult language understanding (<a href="https://super.gluebenchmark.com/leaderboard/" target="_blank">SuperGLUE</a>) leaderboard. 
            [<a href="http://news.whu.edu.cn/info/1015/69135.htm" target="_blank">PR</a>] <br>
         </p></li>
         <li><p>
            [10/2022] One long paper has been accepted by Findings of <a href="https://2022.emnlp.org" target="_blank">EMNLP22</a>. 
            [<a href="https://aclanthology.org/2022.findings-emnlp.300.pdf" target="_blank">Paper</a>] 
            [<a href="https://github.com/WHU-ZQH/FSAM4PLM" target="_blank">Code</a>] <br>
         </p></li>
         <li><p>
            [08/2022] One long paper has been accepted by <a href="https://coling2022.org" target="_blank">COLING22</a>. 
            [<a href="https://aclanthology.org/2022.coling-1.581.pdf" target="_blank">Paper</a>] 
            [<a href="https://github.com/wangbing1416/C3DA" target="_blank">Code</a>]  <br>
         </p></li>
          <li><p>
            [01/2022] Our <a href="https://arxiv.org/pdf/2302.09268.pdf" target="_blank">Vega v1</a> model got <b>1st</b> place on the General Language Understanding Evaluation (<a href="https://gluebenchmark.com/leaderboard/" target="_blank">GLUE</a>) leaderboard. 
            [<a href="http://ai.whu.edu.cn/index.php?a=show&catid=4&id=76&lang=1" target="_blank">PR</a>] <br>
         </p></li>
          <li><p>
            [09/2021] Start my internship in JD Explore Academy. <br>
         </p></li>
        </ul>
    </div> <br>
    
    <div>
        <h2><hr><a name="job"></a>Job / Internship Experience</h2>
        <ul>
            <li><p>
                <b>JD Explore Academy</b>, September 2021 -- May 2023 <br>
                Research on sufficient/efficient language model pretraining and fine-tuning in JDEA-NLP group, advised by <a href="http://liamding.cc/" target="_blank">Liang Ding</a>
		    and <a href="https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=zh-CN" target="_blank">Dacheng Tao</a>.
            </p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="edu"></a>Education</h2>
        <ul>
            <li><p>
                <b>Wuhan University</b>, September 2020 -- Present<br>
                Ph.D. Student in School of Computer Science, Wuhan, China.<br>
                Supervised by <a href="https://scholar.google.com/citations?user=Shy1gnMAAAAJ&hl=zh-CN" target="_blank">Bo Du</a> and 
		<a href="https://scholar.google.com/citations?user=wN-rIgIAAAAJ&hl=en" target="_blank">Juhua Liu</a>.
            </p></li>
            <li><p>
                <b>Wuhan University</b>, September 2016 -- July 2020<br>
                Bachelor, Wuhan, China.
            </p></li>
        </ul>
    </div>
    
     <div>
	<h2><hr><a name="award"></a>Honors &amp; Awards</h2>
	<ul>
		<li>2024.10 &nbsp;&nbsp; First Prize in Academic Innovation; &nbsp;&nbsp; Wuhan University;</li>
		<li>2023.12 &nbsp;&nbsp; Pacemaker to Outstanding Postgraduate; &nbsp;&nbsp; Wuhan University;</li>
		<li>2023.11 &nbsp;&nbsp; Lei Jun Excellence Scholarship; &nbsp;&nbsp; Wuhan University;</li>
		<li>2023.04 &nbsp;&nbsp; 2022 Technology Golden Award; &nbsp;&nbsp; JD Explore Academy;</li>
		<li>2022.01 &nbsp;&nbsp; Outstanding Intern; &nbsp;&nbsp; JD Explore Academy;</li>
		<li>2021.10 &nbsp;&nbsp; Leijun Scholarship; &nbsp;&nbsp; Wuhan University;</li>
		<li>2020.06 &nbsp;&nbsp; Excellent Undergraduate Graduates; &nbsp;&nbsp; Wuhan University;</li>
		<li>2019.10 &nbsp;&nbsp; National Encouragement Scholarship; &nbsp;&nbsp; Wuhan University;</li>
		<li>2018.10 &nbsp;&nbsp; National Encouragement Scholarship; &nbsp;&nbsp; Wuhan University;</li>
		<li>2017.10 &nbsp;&nbsp; National Encouragement Scholarship; &nbsp;&nbsp; Wuhan University;</li>
	</ul>
	</div>
		<div id="footer">
			<div id="footer-text"></div>
		</div>
    
    <div align='center'>
		<br>
	    <a href="https://info.flagcounter.com/iVZt">
		<img src="https://s01.flagcounter.com/count2/iVZt/bg_FFFFFF/txt_000000/border_CCCCCC/columns_5/maxflags_10/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" 
		alt="Flag Counter" border="0"></a>
	</div>
</td>
</tr>
</table>
</body>
</html>
